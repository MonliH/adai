{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T01:38:37.283771Z",
     "start_time": "2020-02-18T01:38:36.679527Z"
    }
   },
   "source": [
    "# MRI Residual Convolutional Neural Network\n",
    "This is the resnet model for the AD pre-diagnosis with artificial intelligence. Uses MRI data, which is 3D. Uses pretrained [medicalnet](https://github.com/Tencent/MedicalNet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T10:30:05.003481Z",
     "start_time": "2020-03-09T10:30:04.998298Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "from sklearn import preprocessing\n",
    "from torchvision import transforms, utils\n",
    "import adabound\n",
    "import numpy as np\n",
    "\n",
    "import nibabel as nib\n",
    "import random\n",
    "\n",
    "import torchio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T10:30:05.179287Z",
     "start_time": "2020-03-09T10:30:05.176040Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"MedicalNet/\")\n",
    "import model as mn\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T10:30:05.743372Z",
     "start_time": "2020-03-09T10:30:05.739369Z"
    }
   },
   "outputs": [],
   "source": [
    "dir(mn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T10:30:05.964815Z",
     "start_time": "2020-03-09T10:30:05.959870Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use the GPU if there is one, otherwise CPU\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "CSV_DIR = \"./scores.csv\"\n",
    "DATA_DIR = \"./mri_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T10:30:06.183143Z",
     "start_time": "2020-03-09T10:30:06.159265Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(CSV_DIR)\n",
    "norm_df = df[[\"mmse\", \"cdr\", \"ageAtEntry\"]]\n",
    "\n",
    "std_scale = preprocessing.StandardScaler().fit(norm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Management\n",
    "Handle CSV diagnosis/signs and get an iterator of brain scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T10:30:06.546457Z",
     "start_time": "2020-03-09T10:30:06.537485Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_scores(ID, date):\n",
    "    scores = []\n",
    "    for index, row in df[df[\"Subject\"].str.contains(ID)].iterrows():\n",
    "        cur_date = int(row[\"ADRC_ADRCCLINICALDATA ID\"].split(\"_\")[-1][1:])\n",
    "        if cur_date > date:\n",
    "            if cur_date > date:\n",
    "                if pd.isna(row[\"mmse\"]): row[\"mmse\"] = 30\n",
    "                if pd.isna(row[\"cdr\"]): row[\"cdr\"] = 0\n",
    "                data = {\n",
    "                    'mmse':  [row[\"mmse\"]],\n",
    "                    'cdr':  [row[\"cdr\"]],\n",
    "                    'ageAtEntry': [row[\"ageAtEntry\"]+cur_date/365]\n",
    "                }\n",
    "\n",
    "                curr_df = std_scale.transform(pd.DataFrame(data, columns=[\"mmse\", \"cdr\", \"ageAtEntry\"]))\n",
    "\n",
    "                scores.append((cur_date-date, curr_df[0][0], curr_df[0][1], curr_df[0][2]))\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T10:30:06.802418Z",
     "start_time": "2020-03-09T10:30:06.771621Z"
    }
   },
   "outputs": [],
   "source": [
    "get_scores('OAS30001', 129)  # testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T10:30:06.956732Z",
     "start_time": "2020-03-09T10:30:06.948435Z"
    }
   },
   "outputs": [],
   "source": [
    "def list_brains():\n",
    "    for file in glob.glob(f\"{DATA_DIR}OAS3[0-9][0-9][0-9][0-9]_MR_d[0-9][0-9][0-9][0-9]/anat[0-9]/sub-OAS3[0-9][0-9][0-9][0-9]_ses-d[0-9][0-9][0-9][0-9]_run-[0-9][0-9]_T1w.nii.gz\"):\n",
    "        yield (file, file.split(\"/\")[2].split(\"_\")[0], int(file.split(\"/\")[2].split(\"_\")[2][1:]))\n",
    "\n",
    "def get_brains():\n",
    "    for brain in list_brains():\n",
    "        for score in get_scores(brain[1], brain[2]):\n",
    "            yield (brain[0], brain[1], brain[2]) + score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dataset\n",
    "Create an iterable dataset with brain data inheriting from `torch.utils.data.Dataset`. Dataset len is `3594`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T10:30:07.406173Z",
     "start_time": "2020-03-09T10:30:07.396895Z"
    }
   },
   "outputs": [],
   "source": [
    "class BrainsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        self.transform = transform\n",
    "        self.brains = []\n",
    "        brain_files = []\n",
    "        for brain_name in get_brains():\n",
    "            if get_scores(*brain_name[1:3]) != []:\n",
    "                self.brains.append(brain_name)\n",
    "                brain_files.append(torchio.Subject(\n",
    "                    torchio.Image(\"MRI\", brain_name[0], torchio.INTENSITY),\n",
    "                ))\n",
    "        self.images_dataset = torchio.ImagesDataset(brain_files)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.brains)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.brains[index][3], self.brains[index][4], self.brains[index][5], self.brains[index][6], self.transform(self.images_dataset[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T20:44:03.363326Z",
     "start_time": "2020-02-18T20:44:03.357375Z"
    }
   },
   "source": [
    "## Create Data Preprocessing and Cropping and Data Augmentation\n",
    "Crop images to (128, 128, 63, 24)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T10:30:07.812134Z",
     "start_time": "2020-03-09T10:30:07.805782Z"
    }
   },
   "outputs": [],
   "source": [
    "class Rescaledef:\n",
    "    \"\"\"Rescale the image in a sample to a given size.\"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, brain):\n",
    "        img = transform.resize(brain, self.output_size)\n",
    "\n",
    "        return img\n",
    "\n",
    "\n",
    "class ToTensor:\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        return sample[\"MRI\"][\"data\"][:, :, :, :]\n",
    "\n",
    "class RandomPermute:\n",
    "    def __call__(self, sample):\n",
    "        dim = [1, 2, 3]\n",
    "        random.shuffle(dim)\n",
    "        return sample.permute(0, *dim)\n",
    "\n",
    "from torchio.transforms import (\n",
    "    ZNormalization,\n",
    "    RandomNoise,\n",
    "    RandomFlip,\n",
    "    RandomAffine,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Neural Network\n",
    "Create a sparse cnn module inheriting from `torch.nn.Module`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T10:30:08.331467Z",
     "start_time": "2020-03-09T10:30:08.315719Z"
    }
   },
   "outputs": [],
   "source": [
    "class BidirectionalLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, nIn, nHidden, nOut):\n",
    "        super(BidirectionalLSTM, self).__init__()\n",
    "\n",
    "        self.rnn = nn.LSTM(nIn, nHidden, bidirectional=True)\n",
    "        self.embedding = nn.Linear(nHidden * 2, nOut)\n",
    "\n",
    "    def forward(self, input):\n",
    "        recurrent, _ = self.rnn(input)\n",
    "        T, b, h = recurrent.size()\n",
    "        t_rec = recurrent.view(T * b, h)\n",
    "\n",
    "        output = self.embedding(t_rec)  # [T * b, nOut]\n",
    "        output = output.view(T, b, -1)\n",
    "\n",
    "        return output\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self, resnet):\n",
    "        nn.Module.__init__(self)\n",
    "        self.resnet = resnet.to(DEVICE)\n",
    "        \n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(64002, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            torch.nn.ELU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            torch.nn.ELU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            torch.nn.ELU(),\n",
    "            nn.Linear(128, 16),\n",
    "            nn.BatchNorm1d(16),\n",
    "            torch.nn.ELU(),\n",
    "            nn.Linear(16, 2)\n",
    "        ).to(DEVICE)\n",
    "        \n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "        self.avgpool = nn.AvgPool3d((4, 4, 4), stride=(3, 3, 3))\n",
    "        self.maxpool = nn.AvgPool3d((3, 3, 3), stride=(2, 2, 2))\n",
    "\n",
    "    def forward(self, brain, days_ahead, age):\n",
    "        \n",
    "        c_out = self.resnet(self.maxpool(brain))\n",
    "        \n",
    "        c_out = self.flatten(self.avgpool(c_out))\n",
    "        \n",
    "        c_out = torch.cat([torch.stack([days_ahead, age]).permute(1, 0), c_out], 1).to(DEVICE)\n",
    "        r_out = torch.cuda.FloatTensor(self.linear(c_out)).to(DEVICE)\n",
    "        return r_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T10:30:08.591295Z",
     "start_time": "2020-03-09T10:30:08.566692Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, criterion_test, train_loader, test_loader, writer):\n",
    "    step_num = 0\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "        print('-' * 10)\n",
    "        running_loss = 0\n",
    "        train_iter = iter(train_loader)\n",
    "        \n",
    "        for i, data_brains in enumerate(train_loader):\n",
    "            step_num += 1\n",
    "            scan = data_brains[4].type(torch.cuda.FloatTensor).to(DEVICE)\n",
    "            days_ahead = data_brains[0].type(torch.cuda.FloatTensor).to(DEVICE)\n",
    "            \n",
    "            age = data_brains[3].type(torch.cuda.FloatTensor).to(DEVICE)\n",
    "            real_values = torch.stack([data_brains[1], data_brains[2]]).permute(1, 0).to(DEVICE)\n",
    "\n",
    "            outputs = model(scan, days_ahead, age)\n",
    "\n",
    "            loss = criterion(outputs, real_values)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % 5 == 4:\n",
    "                print(f\"[{epoch + 1} {i + 1}] loss: {running_loss/5}\")\n",
    "                writer.add_scalar(\"Training Loss\", running_loss/5, step_num)\n",
    "                running_loss = 0\n",
    "\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    \n",
    "                    try:\n",
    "                        test_data = next(train_iter)\n",
    "                    except StopIteration:\n",
    "                        train_iter = iter(train_loader)\n",
    "                        test_data = next(train_iter)\n",
    "\n",
    "                    _scan = test_data[4].type(torch.cuda.FloatTensor).to(DEVICE)\n",
    "                    _days_ahead = test_data[0].type(torch.cuda.FloatTensor).to(DEVICE)\n",
    "                    _age = test_data[3].type(torch.cuda.FloatTensor).to(DEVICE)\n",
    "                    _real_values = torch.stack([test_data[1], test_data[2]]).permute(1, 0).to(DEVICE)\n",
    "                    _outputs = model(_scan, _days_ahead, _age)\n",
    "                    writer.add_scalar(\"Test Loss\", criterion_test(_outputs, _real_values), step_num)\n",
    "\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        print(\"Saving model\")\n",
    "        torch.save(model.state_dict(), f\"model_pretrained_cnn/new_model_{epoch}_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T10:30:08.901819Z",
     "start_time": "2020-03-09T10:30:08.894085Z"
    }
   },
   "outputs": [],
   "source": [
    "class Params():\n",
    "    def __init__(self):\n",
    "        self.model = \"resnet\"\n",
    "        self.model_depth = 34\n",
    "        self.input_W = 128\n",
    "        self.input_H = 128\n",
    "        self.input_D = 128\n",
    "        self.resnet_shortcut = \"A\"\n",
    "        self.no_cuda = False\n",
    "        self.gpu_id = [0]\n",
    "        self.n_seg_classes = 128\n",
    "        self.phase = \"train\"\n",
    "        self.pretrain_path = os.getcwd()+\"/MedicalNet/pretrain/resnet_34_23dataset.pth\"\n",
    "        self.new_layer_names = ['upsample1', 'cmp_layer3', 'upsample2', 'cmp_layer2', 'upsample3', 'cmp_layer1', 'upsample4', 'cmp_conv1', 'conv_seg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T10:30:09.480753Z",
     "start_time": "2020-03-09T10:30:09.476719Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 50\n",
    "BATCH_SIZE = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T10:31:42.546635Z",
     "start_time": "2020-03-09T10:30:09.950202Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchio.transforms import (\n",
    "    RandomFlip,\n",
    "    RandomNoise,\n",
    "    RandomMotion,\n",
    "    RandomBiasField,\n",
    "    Rescale,\n",
    "    ToCanonical,\n",
    "    CenterCropOrPad,\n",
    ")\n",
    "\n",
    "from torchvision.transforms import Compose\n",
    "\n",
    "training_transform = Compose([\n",
    "    Rescale((0, 1)),  # so that there are no negative values for RandomMotion\n",
    "    RandomMotion(),\n",
    "    RandomBiasField(),\n",
    "    RandomNoise(std_range=(0, 0.005)),\n",
    "    ToCanonical(),\n",
    "    CenterCropOrPad((256, 256, 256)),\n",
    "    RandomFlip(axes=(0,)),\n",
    "    ToTensor(),\n",
    "    RandomPermute()\n",
    "])\n",
    "\n",
    "dataset = BrainsDataset(training_transform)\n",
    "\n",
    "NUM_INSTANCES = len(dataset)\n",
    "TEST_RATIO = 0.2\n",
    "TEST_SIZE = int(NUM_INSTANCES * TEST_RATIO)\n",
    "TRAIN_SIZE = NUM_INSTANCES - TEST_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T10:31:42.582532Z",
     "start_time": "2020-03-09T10:31:42.548303Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data, test_data = torch.utils.data.random_split(dataset, (TRAIN_SIZE, TEST_SIZE))\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle = True, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle = False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-09T10:30:11.935Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "model, _ = mn.generate_model(Params())\n",
    "\n",
    "model = Net(model)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters())  \n",
    "criterion = torch.nn.MSELoss()\n",
    "criterion_test = torch.nn.MSELoss()\n",
    "writer = SummaryWriter()\n",
    "\n",
    "loss = train(model, optimizer, criterion, criterion_test, train_loader, test_loader, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T10:28:27.468129Z",
     "start_time": "2020-03-09T10:28:18.841Z"
    }
   },
   "outputs": [],
   "source": [
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-02T13:22:25.616Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, data_brains in enumerate(train_loader):\n",
    "    scan = data_brains[4].type(torch.cuda.FloatTensor).to(DEVICE)\n",
    "    days_ahead = data_brains[0].type(torch.cuda.FloatTensor).to(DEVICE)\n",
    "    age = data_brains[3].type(torch.cuda.FloatTensor).to(DEVICE)\n",
    "\n",
    "    writer.add_graph(model, (scan, days_ahead, age))\n",
    "    break\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T13:09:12.468063Z",
     "start_time": "2020-03-05T13:09:11.434653Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model, f\"model_cnn_normal_final_new.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T13:10:18.590524Z",
     "start_time": "2020-03-05T13:10:17.472666Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "event_acc = EventAccumulator(\"./runs/Mar02_08-24-04_linux-desktop/events.out.tfevents.1583155445.linux-desktop.23221.0\")\n",
    "event_acc.Reload()\n",
    "# Show all tags in the log file\n",
    "\n",
    "previous_step = 0\n",
    "writer = SummaryWriter()\n",
    "for i, loss in enumerate(event_acc.Scalars(\"Training_Loss\")):\n",
    "    writer.add_scalar(\"Training_Loss\", loss.value, global_step=i, walltime=loss.wall_time,)\n",
    "\n",
    "for i, loss in enumerate(event_acc.Scalars(\"Test_Loss\")):\n",
    "    writer.add_scalar(\"Test_Loss\", loss.value, global_step=i, walltime=loss.wall_time,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-02T13:22:25.632Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-02T13:22:25.638Z"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for i, data_brains in enumerate(train_loader):\n",
    "        scan = data_brains[4].type(torch.cuda.FloatTensor).to(DEVICE)\n",
    "        days_ahead = data_brains[0].type(torch.cuda.FloatTensor).to(DEVICE)\n",
    "        age = data_brains[3].type(torch.cuda.FloatTensor).to(DEVICE)\n",
    "        real_values = torch.stack([data_brains[1], data_brains[2]]).permute(1, 0).to(DEVICE)\n",
    "\n",
    "        model.eval()\n",
    "        outputs = model(scan[None, 0], days_ahead[None, 0], age[None, 0])\n",
    "        print(f\"Outputs: {outputs}\")\n",
    "        print(f\"Real Values: {real_values}\")\n",
    "\n",
    "        data_pred = {\n",
    "            'mmse':  [outputs[0][0]],\n",
    "            'cdr':  [outputs[0][1]]\n",
    "        }\n",
    "\n",
    "        data_pred = std_scale.inverse_transform(pd.DataFrame(data_pred, columns=[\"mmse\", \"cdr\", \"ageAtEntry\"]))\n",
    "\n",
    "        data_real = {\n",
    "            'mmse':  [real_values[0][0]],\n",
    "            'cdr':  [real_values[0][1]]\n",
    "        }\n",
    "\n",
    "        data_real = std_scale.inverse_transform(pd.DataFrame(data_real, columns=[\"mmse\", \"cdr\", \"ageAtEntry\"]))\n",
    "    \n",
    "        print(data_pred)\n",
    "        print(data_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-02T13:22:25.650Z"
    }
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Dimensions of Data\n",
    "Here we get the dimensions of the data to be cropped\n",
    "\n",
    "Size: \n",
    "```\n",
    "{\n",
    "    (176, 256, 256): 3348, \n",
    "    (256, 256, 128): 1737, \n",
    "    (176, 240, 256): 56, \n",
    "    (175, 256, 256): 8\n",
    "}\n",
    "```\n",
    "\n",
    "5149 Scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-08T12:31:57.995328Z",
     "start_time": "2020-03-08T12:19:16.475324Z"
    }
   },
   "outputs": [],
   "source": [
    "dimensions = {}\n",
    "\n",
    "for brain in get_brains():\n",
    "    shape = nib.load(brain[0]).get_fdata().shape\n",
    "    if shape in dimensions:\n",
    "        dimensions[shape] += 1\n",
    "    else:\n",
    "        dimensions[shape] = 1\n",
    "\n",
    "print(dimensions)\n",
    "\n",
    "nums = 0\n",
    "for num in dimensions.values():\n",
    "    nums+=num\n",
    "nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-08T12:33:57.428603Z",
     "start_time": "2020-03-08T12:31:57.998157Z"
    }
   },
   "outputs": [],
   "source": [
    "smallest, largest = 0, 0\n",
    "\n",
    "for brain in list_brains():\n",
    "    data = nib.load(brain[0]).get_fdata()\n",
    "    \n",
    "    if np.min(data) < smallest:\n",
    "        smallest = np.min(data)\n",
    "    if int(np.max(data)) > largest:\n",
    "        largest = np.max(data)\n",
    "\n",
    "(smallest, largest)\n",
    "# should be (-4401596.0, 4831864.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-02T13:22:25.662Z"
    }
   },
   "outputs": [],
   "source": [
    "for brain in get_brains():\n",
    "    shape = nib.load(brain[0]).get_fdata().shape\n",
    "    if len(shape) == 3:\n",
    "        print(brain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-02T13:22:25.665Z"
    }
   },
   "outputs": [],
   "source": [
    "bad_data = ['../data/sub-OAS30065/ses-d0553/pet/sub-OAS30065_ses-d0553_acq-PIB_pet.nii.gz',\n",
    "'../data/sub-OAS30229/ses-d0101/pet/sub-OAS30229_ses-d0101_acq-PIB_pet.nii.gz',\n",
    "'../data/sub-OAS30253/ses-d3948/pet/sub-OAS30253_ses-d3948_acq-PIB_pet.nii.gz',\n",
    "'../data/sub-OAS30332/ses-d0091/pet/sub-OAS30332_ses-d0091_acq-PIB_pet.nii.gz',\n",
    "'../data/sub-OAS30472/ses-d1278/pet/sub-OAS30472_ses-d1278_acq-PIB_pet.nii.gz',\n",
    "'../data/sub-OAS30498/ses-d0120/pet/sub-OAS30498_ses-d0120_acq-PIB_pet.nii.gz',\n",
    "'../data/sub-OAS30588/ses-d1639/pet/sub-OAS30588_ses-d1639_acq-PIB_pet.nii.gz',\n",
    "'../data/sub-OAS30896/ses-d1601/pet/sub-OAS30896_ses-d1601_acq-PIB_pet.nii.gz'\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "82px",
    "width": "338px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "354px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
